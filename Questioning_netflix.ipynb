{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f1d066",
   "metadata": {},
   "source": [
    "#### a)Preparing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2d424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/03 13:36:58 WARN Utils: Your hostname, loic-Latitude-5580 resolves to a loopback address: 127.0.1.1; using 10.94.68.14 instead (on interface wlp2s0)\n",
      "26/01/03 13:36:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/03 13:36:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: date (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- description: string (nullable = true)\n",
      " |-- duration_min: integer (nullable = true)\n",
      " |-- duration_season: integer (nullable = true)\n",
      "\n",
      "+-------+---------+------------+---------------+----------+--------------------------------------------------------------------------+\n",
      "|type   |duration |duration_min|duration_season|date_added|listed_in                                                                 |\n",
      "+-------+---------+------------+---------------+----------+--------------------------------------------------------------------------+\n",
      "|Movie  |90 min   |90          |NULL           |2021-09-25|[Documentaries]                                                           |\n",
      "|TV Show|2 Seasons|NULL        |2              |2021-09-24|[International TV Shows, TV Dramas, TV Mysteries]                         |\n",
      "|TV Show|1 Season |NULL        |1              |2021-09-24|[Crime TV Shows, International TV Shows, TV Action & Adventure]           |\n",
      "|TV Show|1 Season |NULL        |1              |2021-09-24|[Docuseries, Reality TV]                                                  |\n",
      "|TV Show|2 Seasons|NULL        |2              |2021-09-24|[International TV Shows, Romantic TV Shows, TV Comedies]                  |\n",
      "|TV Show|1 Season |NULL        |1              |2021-09-24|[TV Dramas, TV Horror, TV Mysteries]                                      |\n",
      "|Movie  |91 min   |91          |NULL           |2021-09-24|[Children & Family Movies]                                                |\n",
      "|Movie  |125 min  |125         |NULL           |2021-09-24|[Dramas, Independent Movies, International Movies]                        |\n",
      "|TV Show|9 Seasons|NULL        |9              |2021-09-24|[British TV Shows, Reality TV]                                            |\n",
      "|Movie  |104 min  |104         |NULL           |2021-09-24|[Comedies, Dramas]                                                        |\n",
      "|TV Show|1 Season |NULL        |1              |2021-09-24|[Crime TV Shows, Docuseries, International TV Shows]                      |\n",
      "|TV Show|1 Season |NULL        |1              |2021-09-23|[Crime TV Shows, International TV Shows, TV Action & Adventure]           |\n",
      "|Movie  |127 min  |127         |NULL           |2021-09-23|[Dramas, International Movies]                                            |\n",
      "|Movie  |91 min   |91          |NULL           |2021-09-22|[Children & Family Movies, Comedies]                                      |\n",
      "|TV Show|1 Season |NULL        |1              |2021-09-22|[British TV Shows, Crime TV Shows, Docuseries]                            |\n",
      "|TV Show|4 Seasons|NULL        |4              |2021-09-22|[TV Comedies, TV Dramas]                                                  |\n",
      "|Movie  |67 min   |67          |NULL           |2021-09-22|[Documentaries, International Movies]                                     |\n",
      "|TV Show|2 Seasons|NULL        |2              |2021-09-22|[Crime TV Shows, Spanish-Language TV Shows, TV Dramas]                    |\n",
      "|Movie  |94 min   |94          |NULL           |2021-09-22|[Thrillers]                                                               |\n",
      "|TV Show|1 Season |NULL        |1              |2021-09-22|[International TV Shows, Spanish-Language TV Shows, TV Action & Adventure]|\n",
      "+-------+---------+------------+---------------+----------+--------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import des Biliotheques utiles\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import col, split, regexp_extract, when, to_date, explode, count, dense_rank, sum, countDistinct, year, avg, size\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler , StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "\n",
    "#Creation de d'une Session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark_netflix\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Considerer la premiere lignes comme le nom des colonnes. Utiliser les donnes pour deviner le datatype.  \n",
    "#Lire les fichier csv est tranformer les donnees en dataframe.\n",
    "\n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"netflix.csv\")\n",
    "\n",
    "#creation de la colonne duration minutes avec les \"durations\" qui sont en minutes\n",
    "df = df.withColumn(\n",
    "    \"duration_min\",\n",
    "    when(\n",
    "        col(\"duration\").contains(\"min\"),\n",
    "        regexp_extract(col(\"duration\"), r\"(\\d+)\", 1).cast(\"int\")\n",
    "    )\n",
    ")\n",
    "\n",
    "#creation de la colonne duration season  avec les \"durations\" qui sont en saisons\n",
    "df = df.withColumn(\n",
    "    \"duration_season\",\n",
    "    when(\n",
    "        col(\"duration\").contains(\"Season\"),\n",
    "        regexp_extract(col(\"duration\"), r\"(\\d+)\", 1).cast(\"int\")\n",
    "    )\n",
    ")\n",
    "\n",
    "#Changer le type de la colonne date_added au type : date \n",
    "df = df.withColumn(\n",
    "    \"date_added\",\n",
    "    to_date(col(\"date_added\"), \"MMMM d, yyyy\")\n",
    ")\n",
    "\n",
    "#normalisation des catégories dans listed_in en une liste (array de strings)\n",
    "df = df.withColumn(\n",
    "    \"listed_in\",\n",
    "    split(col(\"listed_in\"), \", \")\n",
    ")\n",
    "\n",
    "df.printSchema()  # Types de variables des differentes colonnes du DataFrame\n",
    "\n",
    "df.select(\n",
    "    \"type\", \"duration\", \"duration_min\", \"duration_season\",\n",
    "    \"date_added\", \"listed_in\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee5c7a7",
   "metadata": {},
   "source": [
    "#### b)Les 3 pays qui produisent le plus de titres pour chaque type de contenu (Movie / TV Show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14fadf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+---------+----+\n",
      "|type   |country       |nb_titles|rank|\n",
      "+-------+--------------+---------+----+\n",
      "|Movie  |United States |2739     |1   |\n",
      "|Movie  |India         |962      |2   |\n",
      "|Movie  |United Kingdom|531      |3   |\n",
      "|TV Show|United States |936      |1   |\n",
      "|TV Show|United Kingdom|272      |2   |\n",
      "|TV Show|Japan         |199      |3   |\n",
      "+-------+--------------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top_countries(df: DataFrame) -> DataFrame:\n",
    "    \n",
    "    # Séparer les pays et exploser\n",
    "    df_country = (\n",
    "        df\n",
    "        .withColumn(\"country\", split(col(\"country\"), \", \"))\n",
    "        .withColumn(\"country\", explode(col(\"country\")))\n",
    "    )\n",
    "\n",
    "    #Compter le nombre de titres par type et pays\n",
    "    df_count = (\n",
    "        df_country\n",
    "        .groupBy(\"type\", \"country\")\n",
    "        .agg(count(\"*\").alias(\"nb_titles\"))\n",
    "    )\n",
    "\n",
    "    #Définir la fenêtre de ranking\n",
    "    window_spec = Window.partitionBy(\"type\").orderBy(col(\"nb_titles\").desc())\n",
    "\n",
    "    #Appliquer dense_rank\n",
    "    df_ranked = df_count.withColumn(\n",
    "        \"rank\",\n",
    "        dense_rank().over(window_spec)\n",
    "    )\n",
    "\n",
    "    #Garder les 3 premiers pays par type\n",
    "    result = df_ranked.filter(col(\"rank\") <= 3)\n",
    "\n",
    "    return result\n",
    "\n",
    "df_clean = df.filter(\n",
    "    col(\"type\").isin(\"Movie\", \"TV Show\")\n",
    ")\n",
    "\n",
    "top3 = top_countries(df_clean)\n",
    "top3.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcdc0b",
   "metadata": {},
   "source": [
    "#### c)Pour chaque acteur :Le nombre total de contenus dans lesquels il apparaît ; le nombre de films ; le nombre de séries ; la diversité de genres dans lesquels il apparaît."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98924e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+---------+-----------+---------------+\n",
      "|actor               |total_contents|nb_movies|nb_tv_shows|genre_diversity|\n",
      "+--------------------+--------------+---------+-----------+---------------+\n",
      "|Jordi Mollà         |4             |4        |0          |6              |\n",
      "|Bob Stephenson      |2             |1        |1          |4              |\n",
      "|Soma Saito          |8             |1        |7          |7              |\n",
      "|Keir Gilchrist      |4             |3        |1          |6              |\n",
      "|Oliver Platt        |8             |7        |1          |8              |\n",
      "|Paul Schrier        |10            |4        |6          |4              |\n",
      "|Yuki Ono            |7             |0        |7          |4              |\n",
      "|Eri Kamataki        |2             |1        |1          |6              |\n",
      "|Kartar Cheema       |3             |3        |0          |4              |\n",
      "|Wayne Kramer        |1             |1        |0          |2              |\n",
      "|Genesis Rodriguez   |5             |4        |1          |7              |\n",
      "|Catherine Sutherland|3             |0        |3          |1              |\n",
      "|Chang Zhang-xing    |2             |1        |1          |6              |\n",
      "|Shauna MacDonald    |2             |2        |0          |4              |\n",
      "|Valarie Pettiford   |4             |3        |1          |4              |\n",
      "|Sarah Levy          |2             |1        |1          |3              |\n",
      "|Brian Jordan Alvarez|1             |0        |1          |2              |\n",
      "|Bobby Andrews       |2             |2        |0          |4              |\n",
      "|Ian Ogilvy          |1             |1        |0          |1              |\n",
      "|Stephen Root        |8             |5        |3          |9              |\n",
      "+--------------------+--------------+---------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def actor_stats(df: DataFrame) -> DataFrame:\n",
    "\n",
    "    #Explosion des acteurs\n",
    "    df_actor = (\n",
    "        df\n",
    "        .withColumn(\"actor\", split(col(\"cast\"), \", \"))\n",
    "        .withColumn(\"actor\", explode(col(\"actor\")))\n",
    "    )\n",
    "\n",
    "    #Comptages des contenus, films et séries\n",
    "    stats_basic = (\n",
    "        df_actor\n",
    "        .groupBy(\"actor\")\n",
    "        .agg(\n",
    "            countDistinct(\"show_id\").alias(\"total_contents\"),\n",
    "            sum(when(col(\"type\") == \"Movie\", 1).otherwise(0)).alias(\"nb_movies\"),\n",
    "            sum(when(col(\"type\") == \"TV Show\", 1).otherwise(0)).alias(\"nb_tv_shows\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #Explosion des genres pour la diversité\n",
    "    df_actor_genre = df_actor.withColumn(\"genre\", explode(col(\"listed_in\")))\n",
    "\n",
    "    stats_genre = (\n",
    "        df_actor_genre\n",
    "        .groupBy(\"actor\")\n",
    "        .agg(countDistinct(\"genre\").alias(\"genre_diversity\"))\n",
    "    )\n",
    "\n",
    "    #Jointure pour tout combiner\n",
    "    stats = stats_basic.join(stats_genre, on=\"actor\", how=\"left\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "actor_df = actor_stats(df_clean)\n",
    "actor_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a11a0a",
   "metadata": {},
   "source": [
    "#### d)Le top 10 des couples d’acteurs collaborant le plus fréquemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b0b841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+-----------------+\n",
      "|actor_1       |actor_2      |nb_collaborations|\n",
      "+--------------+-------------+-----------------+\n",
      "|Julie Tejwani |Rupa Bhimani |31               |\n",
      "|Julie Tejwani |Rajesh Kava  |24               |\n",
      "|Rajesh Kava   |Rupa Bhimani |22               |\n",
      "|Jigna Bhardwaj|Julie Tejwani|21               |\n",
      "|Jigna Bhardwaj|Rupa Bhimani |20               |\n",
      "|Jigna Bhardwaj|Rajesh Kava  |20               |\n",
      "|Julie Tejwani |Vatsal Dubey |18               |\n",
      "|Rupa Bhimani  |Vatsal Dubey |18               |\n",
      "|Jigna Bhardwaj|Vatsal Dubey |18               |\n",
      "|Rajesh Kava   |Vatsal Dubey |17               |\n",
      "+--------------+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def actor_pairs(df: DataFrame) -> DataFrame:\n",
    "    \n",
    "    #Explosion des acteurs\n",
    "    df_actor = df.withColumn(\"actor\", split(col(\"cast\"), \", \")) \\\n",
    "                 .withColumn(\"actor\", explode(col(\"actor\")))\n",
    "    \n",
    "    #CrossJoin sur show_id pour former tous les couples\n",
    "    df_pairs = df_actor.alias(\"a\").join(\n",
    "        df_actor.alias(\"b\"),\n",
    "        on=\"show_id\"\n",
    "    )\n",
    "    \n",
    "    #Éviter auto-collaboration et doublons\n",
    "    df_pairs = df_pairs.filter(col(\"a.actor\") < col(\"b.actor\"))\n",
    "    \n",
    "    #Compter le nombre de collaborations\n",
    "    df_pairs_count = df_pairs.groupBy(\n",
    "        col(\"a.actor\").alias(\"actor_1\"),\n",
    "        col(\"b.actor\").alias(\"actor_2\")\n",
    "    ).agg(\n",
    "        count(\"*\").alias(\"nb_collaborations\")\n",
    "    )\n",
    "    \n",
    "    #Top 10\n",
    "    top10_pairs = df_pairs_count.orderBy(col(\"nb_collaborations\").desc()).limit(10)\n",
    "    \n",
    "    return top10_pairs\n",
    "\n",
    "top_collabs = actor_pairs(df_clean)\n",
    "top_collabs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc48199",
   "metadata": {},
   "source": [
    "#### e)Le nombre de nouveaux contenus ajoutés par mois ; la croissance (ou décroissance) des ajouts Netflix par un modèle linéaire simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/03 13:48:37 WARN Instrumentation: [13ba8cd9] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------------------+\n",
      "|year|nb_added|regression_trend   |\n",
      "+----+--------+-------------------+\n",
      "|2008|2       |-468.3428571370314 |\n",
      "|2009|2       |-300.8065934017068 |\n",
      "|2010|1       |-133.27032966632396|\n",
      "|2011|13      |34.26593406905886  |\n",
      "|2012|3       |201.80219780438347 |\n",
      "|2013|10      |369.3384615397663  |\n",
      "|2014|23      |536.8747252750909  |\n",
      "|2015|72      |704.4109890104737  |\n",
      "|2016|418     |871.9472527458565  |\n",
      "|2017|1162    |1039.4835164811811 |\n",
      "|2018|1623    |1207.019780216564  |\n",
      "|2019|1997    |1374.5560439518886 |\n",
      "|2020|1872    |1542.0923076872714 |\n",
      "|2021|1491    |1709.628571422596  |\n",
      "+----+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def time_analysis(df: DataFrame) -> DataFrame:\n",
    "    \n",
    "\n",
    "    # Nettoyage\n",
    "    df_cleaned = df.filter(col(\"date_added\").isNotNull())\n",
    "\n",
    "    #Moyenne annuelle des nouvelles productions (release_year)\n",
    "    df_annual_prod = df_cleaned.groupBy(\"release_year\").agg(count(\"*\").alias(\"nb_releases\"))\n",
    "    avg_annual = df_annual_prod.agg(avg(\"nb_releases\").alias(\"avg_productions\")).collect()[0][0]\n",
    "\n",
    "    #Nombre de contenus ajoutés par année\n",
    "    df_yearly = df_cleaned.withColumn(\"year\", year(col(\"date_added\"))) \\\n",
    "                          .groupBy(\"year\") \\\n",
    "                          .agg(count(\"*\").alias(\"nb_added\"))\n",
    "\n",
    "    #Vectorisation pour ML\n",
    "    assembler = VectorAssembler(inputCols=[\"year\"], outputCol=\"features\")\n",
    "    df_yearly_feat = assembler.transform(df_yearly)\n",
    "\n",
    "    #Régression linéaire (croissance/décroissance)\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"nb_added\")\n",
    "    lr_model = lr.fit(df_yearly_feat)\n",
    "    df_pred = lr_model.transform(df_yearly_feat) \\\n",
    "                      .withColumnRenamed(\"prediction\", \"regression_trend\")\n",
    "\n",
    "\n",
    "    df_final = df_pred.withColumn(\"avg_productions\", col(\"regression_trend\")*0 + avg_annual) \\\n",
    "                      .select(\"year\", \"nb_added\", \"regression_trend\") \\\n",
    "                      .orderBy(\"year\")\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "df_time = time_analysis(df_clean)\n",
    "df_time.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff68298",
   "metadata": {},
   "source": [
    "#### f)Réalisation d'un clustering K-Means basé sur :la durée en minutes,l’année de sortie, la taille du casting. k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ed7ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------------+-------+------------+------------+---------+-------+\n",
      "|show_id|title                                              |type   |duration_min|release_year|size_cast|cluster|\n",
      "+-------+---------------------------------------------------+-------+------------+------------+---------+-------+\n",
      "|s1     |Dick Johnson Is Dead                               |Movie  |90.0        |2020.0      |0.0      |3      |\n",
      "|s2     |Blood & Water                                      |TV Show|0.0         |2021.0      |19.0     |0      |\n",
      "|s3     |Ganglands                                          |TV Show|0.0         |2021.0      |9.0      |0      |\n",
      "|s4     |Jailbirds New Orleans                              |TV Show|0.0         |2021.0      |0.0      |3      |\n",
      "|s5     |Kota Factory                                       |TV Show|0.0         |2021.0      |8.0      |0      |\n",
      "|s6     |Midnight Mass                                      |TV Show|0.0         |2021.0      |16.0     |0      |\n",
      "|s7     |My Little Pony: A New Generation                   |Movie  |91.0        |2021.0      |10.0     |1      |\n",
      "|s8     |Sankofa                                            |Movie  |125.0       |1993.0      |8.0      |1      |\n",
      "|s9     |The Great British Baking Show                      |TV Show|0.0         |2021.0      |4.0      |3      |\n",
      "|s10    |The Starling                                       |Movie  |104.0       |2021.0      |11.0     |1      |\n",
      "|s11    |Vendetta: Truth, Lies and The Mafia                |TV Show|0.0         |2021.0      |0.0      |3      |\n",
      "|s12    |Bangkok Breaking                                   |TV Show|0.0         |2021.0      |25.0     |0      |\n",
      "|s13    |Je Suis Karl                                       |Movie  |127.0       |2021.0      |11.0     |1      |\n",
      "|s14    |Confessions of an Invisible Girl                   |Movie  |91.0        |2021.0      |10.0     |1      |\n",
      "|s15    |Crime Stories: India Detectives                    |TV Show|0.0         |2021.0      |0.0      |3      |\n",
      "|s16    |Dear White People                                  |TV Show|0.0         |2021.0      |8.0      |0      |\n",
      "|s17    |Europe's Most Dangerous Man: Otto Skorzeny in Spain|Movie  |67.0        |2020.0      |0.0      |3      |\n",
      "|s18    |Falsa identidad                                    |TV Show|0.0         |2020.0      |12.0     |0      |\n",
      "|s19    |Intrusion                                          |Movie  |94.0        |2021.0      |10.0     |1      |\n",
      "|s20    |Jaguar                                             |TV Show|0.0         |2021.0      |8.0      |0      |\n",
      "+-------+---------------------------------------------------+-------+------------+------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cluster_contents(df: DataFrame) -> DataFrame:\n",
    "\n",
    "    #Fonction utilitaire pour nettoyer les colonnes numériques\n",
    "    def clean_double(df, col_name):\n",
    "        return df.withColumn(\n",
    "            col_name,\n",
    "            when(col(col_name).rlike(\"^[0-9]+$\"), col(col_name).cast(DoubleType()))\n",
    "            .otherwise(0.0)\n",
    "        )\n",
    "    \n",
    "    #Nettoyage des colonnes\n",
    "    df_cleaned = df\n",
    "\n",
    "    # duration_min : garder uniquement les nombres, sinon 0\n",
    "    df_cleaned = clean_double(df_cleaned, \"duration_min\")\n",
    "\n",
    "    # release_year : garder uniquement les nombres, sinon 0\n",
    "    df_cleaned = clean_double(df_cleaned, \"release_year\")\n",
    "\n",
    "    # size_cast : nombre d'acteurs, 0 si cast vide ou null\n",
    "    df_cleaned = df_cleaned.withColumn(\n",
    "        \"size_cast\",\n",
    "        when(col(\"cast\").isNotNull(), size(split(col(\"cast\"), \", \"))).otherwise(0.0).cast(DoubleType())\n",
    "    )\n",
    "\n",
    "    #VectorAssembler\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[\"duration_min\", \"release_year\", \"size_cast\"],\n",
    "        outputCol=\"features_vec\"\n",
    "    )\n",
    "    df_vect = assembler.transform(df_cleaned)\n",
    "\n",
    "    #StandardScaler\n",
    "    scaler = StandardScaler(\n",
    "        inputCol=\"features_vec\",\n",
    "        outputCol=\"features_scaled\",\n",
    "        withMean=True,\n",
    "        withStd=True\n",
    "    )\n",
    "    scaler_model = scaler.fit(df_vect)\n",
    "    df_scaled = scaler_model.transform(df_vect)\n",
    "\n",
    "    #K-Means clustering\n",
    "    kmeans = KMeans(featuresCol=\"features_scaled\", predictionCol=\"cluster\", k=4, seed=42)\n",
    "    kmeans_model = kmeans.fit(df_scaled)\n",
    "    df_clustered = kmeans_model.transform(df_scaled)\n",
    "\n",
    "    #DataFrame final\n",
    "    df_final = df_clustered.select(\n",
    "        \"show_id\",\n",
    "        \"title\",\n",
    "        \"type\",\n",
    "        \"duration_min\",\n",
    "        \"release_year\",\n",
    "        \"size_cast\",\n",
    "        \"cluster\"\n",
    "    )\n",
    "\n",
    "    return df_final\n",
    "\n",
    "df_clusters = cluster_contents(df)\n",
    "df_clusters.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
